---
title: "Topological Sorting And Autograd"
date: 2024-09-19 08:00:00 +00:00
tags: [coding, graph]
toc: false
---

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

Firms love to force candidates to go through [bizarre humiliation rituals](https://leetcode.com/problemset/) during interviews. One of these was to implement a topsort algo for their autograd engine. 

The topsort alg only works on [directed acyclic graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) where each node represents a variable and each edge represents a dependency. The goal is to sort the nodes in "_topological order_", i.e. such that if there is an edge from node $u$ to node $v$, then $u$ comes before $v$ in the sorted list of nodes. (Needs to be directed because the whole point is to sort dependencies, and it needs to be acyclic because otherwise we'd run into contradictions.)

If we consider a simple graph like so : 

<figure style="text-align: center;">
  <img src="/assets/img/topsort/graph.png" alt="ui" style="width: 60%; max-width: 500px;">
</figure>

Then the expected output would be `['a', 'b', 'c', 'd']` or `['b', 'a', 'c', 'd']` since `c` depends on both `a` and `b` and `d` depends on `c`.

## DFS

Main tool to solve this problem is the [Depth First Search (DFS)](https://en.wikipedia.org/wiki/Depth-first_search) algorithm. Courtesy of Claude : 

>Imagine you're exploring a big maze made of connected rooms. Each room is connected to other rooms by doors. Your goal is to visit every single room in the maze. Here's how DFS works:
>
>- You start in one room. This is your starting point.
>- You look around and see all the doors in the room.
>- You pick one door and go through it into the next room.
>- In this new room, you do the same thing: look for doors and pick one.
>- You keep doing this, always choosing a new door if there is one.
>- Sometimes you'll end up in a room with no new doors (all doors lead to rooms you've already visited). When this happens, you go back to the previous room.
>- In the previous room, you look for any doors you haven't gone through yet. If you find one, you go through it.
>- If there are no new doors in that room either, you go back again.
>- You keep doing this until you've visited every single room and tried every single door.
>
>The key ideas are:
>
>Always go as deep as you can before coming back.
>Keep track of which rooms you've visited so you don't go in circles.
>When you can't go forward anymore, you go back (this is called "backtracking").
>
> In our code, the "rooms" are the nodes in our graph, and the "doors" are the connections between nodes. The DFS algorithm helps us visit all the nodes in a specific order, prioritizing the deepest nodes first.

A simple implementation of the DFS algorithm in Python would look like this : 

```python
graph = {
    'a': ['c'],
    'b': ['c'],
    'c': ['d'],
    'd': []
}

stack = []
visited = {node: False for node in graph}

def dfs(graph, node, visited, stack):
    visited[node] = True
    for children in graph[node]:
        if not visited[children]:
            dfs(graph, children, visited, stack)
    stack.append(node)

for node in graph:
    if not visited[node]:
        dfs(graph, node, visited, stack)
print(stack)
# >> ['d', 'c', 'a', 'b']
```
In the main loop, we iterate over all nodes in the graph and call `dfs`. The `dfs` appends the current node to the stack only after all its children have been visited. So that would be :
1) `a` -> dfs(`c`) -> dfs(`d`) (forward) -> append(`d`) -> append(`c`) (backtrack) -> append(`a`) (finally append current node)
2) `b` -> dfs(`c`) (already visited so we stop here) -> append(`b`) (append current node)
All nodes have been visited and our stack is `['d', 'c', 'a', 'b']`

## Top Sort

We want to use this stuff in the context of an autograd engine, so we'll represent the graph a bit differently. Instead of a dictionary, we'll just define Nodes, each Node has a list of parents and value.  

```python
class Node:
    def __init__(self, name, value, parents=None):
        self.value = value  # The value of the node (e.g., the result of a computation)
        self.parents = parents if parents else []  # Nodes this node depends on (inputs)
        self.grad = 0  # Gradient for backpropagation
        self.name = name  # node ID
        
    def __repr__(self):
        return f"Node({self.name} : {self.value})"

def topsort(nodes):
    visited = set()
    sorted_nodes = []
    
    def dfs(node):
        if node in visited:
            return
        visited.add(node)
        for parent in node.parents:
            dfs(parent)
        sorted_nodes.append(node)

    for node in nodes:
        dfs(node)
    return sorted_nodes[::-1]  # Reverse the list to get the correct order

# Our graph as a list of nodes
a = Node("a", 3)
b = Node("b", 4)
c = Node("c", a.value + b.value, parents=[a, b])  # c = a + b
d = Node("d", c.value * 2, parents=[c])  # d = c * 2
nodes = [a, b, c, d]

print(topsort(nodes))
# >>> [Node(d : 14), Node(c : 7), Node(b : 4), Node(a : 3)]
```

Why is it useful ? If we have a sorted computation graph, we can easily compute the gradients of each node with respect to the final output. Something like that : 

```python
import math

class Node:
    def __init__(self, value, parents=None, operation=None):
        self.value = value
        self.parents = parents if parents else []
        self.operation = operation
        self.grad = 0.0
        self.backward = lambda: None

    def __repr__(self):
        return f"Node(value={self.value}, grad={self.grad})"

def topsort(node):
    visited, sorted_nodes = set(), []
    def dfs(n):
        if n not in visited:
            visited.add(n)
            for parent in n.parents:
                dfs(parent)
            sorted_nodes.append(n)
    dfs(node)
    return sorted_nodes

# Go through the sorted nodes in reverse order and compute gradients
def backward(node):
    sorted_nodes = topsort(node)
    node.grad = 1.0
    for n in reversed(sorted_nodes):
        n.backward()

# Basic operations and their gradients
def add(a, b):
    out = Node(a.value + b.value, parents=[a, b], operation='+')
    def _backward():
        a.grad += out.grad
        b.grad += out.grad
    out.backward = _backward
    return out

def multiply(a, b):
    out = Node(a.value * b.value, parents=[a, b], operation='*')
    def _backward():
        a.grad += b.value * out.grad
        b.grad += a.value * out.grad
    out.backward = _backward
    return out

def power(a, x):
    out = Node(a.value ** x, parents=[a], operation=f'**{x}')
    def _backward():
        a.grad += x * (a.value ** (x - 1)) * out.grad
    out.backward = _backward
    return out

def sqrt(a):
    out = Node(math.sqrt(a.value), parents=[a], operation='sqrt')
    def _backward():
        a.grad += out.grad / (2 * math.sqrt(a.value))
    out.backward = _backward
    return out

def exp(a):
    out = Node(math.exp(a.value), parents=[a], operation='exp')
    def _backward():
        a.grad += out.value * out.grad
    out.backward = _backward
    return out

def log(a):
    out = Node(math.log(a.value), parents=[a], operation='log')
    def _backward():
        a.grad += out.grad / a.value
    out.backward = _backward
    return out

a = Node(3)
b = Node(4)
c = add(a, b)  # c = a + b
d = multiply(c, Node(2))  # d = c * 2
e = power(d, 0.5)  # e = sqrt(d)
f = sqrt(e)  # f = sqrt(e)
g = exp(f)  # g = exp(f)
h = log(g)  # h = log(g)

# Forward pass
print(f"Forward pass result: {h.value}")

# Backward pass
backward(h)

print("Gradients:")
for node, name in zip([h, g, f, e, d, c, a, b], "hgfedcab"):
    print(f"{name}: {node.grad}")
```

TODO : finish and reproduce https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html + better explain the difference topsort and dfs
